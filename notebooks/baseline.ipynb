{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3555a676-fa7c-4d8d-96c7-3a45dd11421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 20 authors: [9248, 898, 65, 59, 761, 37, 1961, 838, 54, 6202, 708, 2858, 30, 23, 34, 120, 79, 220, 7862, 125]\n",
      "Test Doc 1468: True=54 | Pred=54\n",
      "Test Doc 853: True=220 | Pred=898\n",
      "Test Doc 229: True=2858 | Pred=23\n",
      "Test Doc 925: True=59 | Pred=23\n",
      "Test Doc 1437: True=9248 | Pred=34\n",
      "Test Doc 659: True=125 | Pred=125\n",
      "Test Doc 43: True=37 | Pred=23\n",
      "Test Doc 899: True=708 | Pred=898\n",
      "Test Doc 419: True=30 | Pred=125\n",
      "Test Doc 1150: True=898 | Pred=898\n",
      "Test Doc 1107: True=761 | Pred=898\n",
      "Test Doc 418: True=30 | Pred=838\n",
      "Test Doc 420: True=30 | Pred=120\n",
      "Test Doc 846: True=220 | Pred=220\n",
      "Test Doc 1435: True=9248 | Pred=898\n",
      "Test Doc 1465: True=34 | Pred=34\n",
      "Test Doc 6: True=65 | Pred=65\n",
      "Test Doc 1313: True=7862 | Pred=7862\n",
      "Test Doc 1451: True=34 | Pred=2858\n",
      "Test Doc 45: True=37 | Pred=23\n",
      "Test Doc 1153: True=898 | Pred=898\n",
      "Test Doc 314: True=1961 | Pred=838\n",
      "Test Doc 1097: True=761 | Pred=761\n",
      "Test Doc 53: True=37 | Pred=37\n",
      "Test Doc 1297: True=7862 | Pred=7862\n",
      "Test Doc 1476: True=54 | Pred=54\n",
      "Test Doc 619: True=79 | Pred=898\n",
      "Test Doc 940: True=59 | Pred=898\n",
      "Test Doc 1298: True=7862 | Pred=7862\n",
      "Test Doc 900: True=708 | Pred=120\n",
      "Test Doc 1489: True=54 | Pred=54\n",
      "Test Doc 650: True=125 | Pred=120\n",
      "Test Doc 766: True=120 | Pred=898\n",
      "Test Doc 8: True=65 | Pred=23\n",
      "Test Doc 14: True=65 | Pred=898\n",
      "Test Doc 63: True=37 | Pred=30\n",
      "Test Doc 300: True=1961 | Pred=838\n",
      "Test Doc 13: True=65 | Pred=23\n",
      "Test Doc 307: True=1961 | Pred=1961\n",
      "Test Doc 186: True=838 | Pred=761\n",
      "Test Doc 292: True=1961 | Pred=838\n",
      "Test Doc 1434: True=9248 | Pred=9248\n",
      "Test Doc 309: True=1961 | Pred=898\n",
      "Test Doc 2: True=65 | Pred=65\n",
      "Test Doc 1159: True=898 | Pred=898\n",
      "Test Doc 926: True=59 | Pred=59\n",
      "Test Doc 909: True=708 | Pred=23\n",
      "Test Doc 717: True=6202 | Pred=838\n",
      "Test Doc 1193: True=23 | Pred=23\n",
      "Test Doc 1456: True=34 | Pred=898\n",
      "Test Doc 1166: True=898 | Pred=898\n",
      "Test Doc 221: True=2858 | Pred=125\n",
      "Test Doc 1455: True=34 | Pred=34\n",
      "Test Doc 201: True=838 | Pred=761\n",
      "Test Doc 1429: True=9248 | Pred=898\n",
      "Test Doc 620: True=79 | Pred=1961\n",
      "Test Doc 1425: True=9248 | Pred=2858\n",
      "Test Doc 762: True=120 | Pred=898\n",
      "Test Doc 647: True=125 | Pred=125\n",
      "Test Doc 1304: True=7862 | Pred=7862\n",
      "Test Doc 200: True=838 | Pred=838\n",
      "Test Doc 4: True=65 | Pred=23\n",
      "Test Doc 854: True=220 | Pred=220\n",
      "Test Doc 1089: True=761 | Pred=761\n",
      "Test Doc 416: True=30 | Pred=120\n",
      "Test Doc 606: True=79 | Pred=898\n",
      "Test Doc 208: True=838 | Pred=838\n",
      "Test Doc 764: True=120 | Pred=120\n",
      "Test Doc 905: True=708 | Pred=2858\n",
      "Test Doc 1305: True=7862 | Pred=898\n",
      "Test Doc 924: True=59 | Pred=23\n",
      "Test Doc 929: True=59 | Pred=59\n",
      "Test Doc 1480: True=54 | Pred=120\n",
      "Test Doc 719: True=6202 | Pred=761\n",
      "Test Doc 655: True=125 | Pred=838\n",
      "Test Doc 1206: True=23 | Pred=23\n",
      "Test Doc 0: True=65 | Pred=65\n",
      "Test Doc 615: True=79 | Pred=898\n",
      "Test Doc 299: True=1961 | Pred=838\n",
      "Test Doc 915: True=708 | Pred=838\n",
      "Test Doc 1096: True=761 | Pred=23\n",
      "Test Doc 1460: True=34 | Pred=1961\n",
      "Test Doc 1108: True=761 | Pred=23\n",
      "Test Doc 210: True=2858 | Pred=125\n",
      "Test Doc 895: True=708 | Pred=898\n",
      "Test Doc 941: True=59 | Pred=761\n",
      "Test Doc 214: True=2858 | Pred=898\n",
      "Test Doc 51: True=37 | Pred=30\n",
      "Test Doc 775: True=120 | Pred=120\n",
      "Test Doc 1189: True=23 | Pred=23\n",
      "Test Doc 1307: True=7862 | Pred=7862\n",
      "Test Doc 1422: True=9248 | Pred=838\n",
      "Test Doc 1112: True=761 | Pred=761\n",
      "Test Doc 1146: True=898 | Pred=79\n",
      "Test Doc 1205: True=23 | Pred=23\n",
      "Test Doc 773: True=120 | Pred=120\n",
      "Test Doc 59: True=37 | Pred=23\n",
      "Test Doc 1202: True=23 | Pred=838\n",
      "Test Doc 294: True=1961 | Pred=9248\n",
      "Test Doc 1143: True=898 | Pred=9248\n",
      "Test Doc 712: True=6202 | Pred=6202\n",
      "Test Doc 911: True=708 | Pred=2858\n",
      "Test Doc 718: True=6202 | Pred=898\n",
      "Test Doc 1474: True=54 | Pred=54\n",
      "Test Doc 661: True=125 | Pred=120\n",
      "Test Doc 185: True=838 | Pred=34\n",
      "Test Doc 205: True=838 | Pred=34\n",
      "Test Doc 662: True=125 | Pred=125\n",
      "Test Doc 1488: True=54 | Pred=54\n",
      "Test Doc 207: True=838 | Pred=838\n",
      "Test Doc 421: True=30 | Pred=120\n",
      "Test Doc 617: True=79 | Pred=7862\n",
      "Test Doc 211: True=2858 | Pred=120\n",
      "Test Doc 1162: True=898 | Pred=898\n",
      "Test Doc 1450: True=34 | Pred=7862\n",
      "Test Doc 839: True=220 | Pred=34\n",
      "Test Doc 919: True=59 | Pred=59\n",
      "Test Doc 1196: True=23 | Pred=23\n",
      "Test Doc 224: True=2858 | Pred=708\n",
      "Test Doc 696: True=6202 | Pred=79\n",
      "Test Doc 1482: True=54 | Pred=54\n",
      "Test Doc 756: True=120 | Pred=120\n",
      "Test Doc 413: True=30 | Pred=7862\n",
      "Test Doc 838: True=220 | Pred=30\n",
      "Test Doc 47: True=37 | Pred=37\n",
      "Test Doc 610: True=79 | Pred=761\n",
      "Test Doc 833: True=220 | Pred=23\n",
      "Test Doc 1441: True=9248 | Pred=9248\n",
      "Test Doc 699: True=6202 | Pred=6202\n",
      "Test Doc 1095: True=761 | Pred=7862\n",
      "\n",
      "baseline accuracy: 0.3923\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "# get data\n",
    "INPUT_FILE = \"collection_stage_2.csv\"  \n",
    "TOP_N_WORDS = 500  # features\n",
    "OUTPUT_FILE = \"cleaned_data.csv\"\n",
    "\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as infile, open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    header = infile.readline()  # read header\n",
    "    outfile.write(header)  \n",
    "\n",
    "    for line_num, line in enumerate(infile, start=2):\n",
    "        parts = line.strip().split(\",\", 2)  # split only first 2 commas\n",
    "        if len(parts) == 3:\n",
    "            author, book, sequence = parts\n",
    "            sequence_cleaned = sequence.replace(\",\", \"\")  # remove commas inside sequence\n",
    "            outfile.write(f\"{author},{book},{sequence_cleaned}\\n\")\n",
    "        else:\n",
    "            print(f\"skip line {line_num}: {line.strip()}\")\n",
    "\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "\n",
    "# cleans\n",
    "df = df[df['sequence'].notnull()]\n",
    "\n",
    "# clean to read csv\n",
    "def clean_text(text):\n",
    "    text = text.replace(\",\", \"\")  # remove commas\n",
    "    return text\n",
    "\n",
    "df['sequence'] = df['sequence'].apply(clean_text)\n",
    "\n",
    "def tokenize(text):\n",
    "    return [w.lower() for w in text.split()]\n",
    "\n",
    "# build vocab\n",
    "all_tokens = []\n",
    "for text in df['sequence']:\n",
    "    all_tokens.extend(tokenize(text))\n",
    "\n",
    "word_freq = Counter(all_tokens)\n",
    "vocab = [word for word, _ in word_freq.most_common(TOP_N_WORDS)]\n",
    "vocab_idx = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "\n",
    "# frequency vec tor\n",
    "def extract_freq_vector(text, vocab_idx):\n",
    "    tokens = tokenize(text)\n",
    "    freqs = Counter(tokens)\n",
    "    vec = np.zeros(len(vocab_idx))\n",
    "    for word, count in freqs.items():\n",
    "        if word in vocab_idx:\n",
    "            vec[vocab_idx[word]] = count\n",
    "    if vec.sum() > 0:\n",
    "        vec /= vec.sum()  # normalization\n",
    "    return vec\n",
    "    \n",
    "TOP_N_AUTHORS = 20\n",
    "\n",
    "# contribtutions of each authr\n",
    "author_counts = df['author'].value_counts()\n",
    "\n",
    "# top N author (20)\n",
    "top_authors = author_counts.nlargest(TOP_N_AUTHORS).index.tolist()\n",
    "\n",
    "print(f\"Selected top {TOP_N_AUTHORS} authors: {top_authors}\")\n",
    "\n",
    "# change df.less authors\n",
    "df = df[df['author'].isin(top_authors)]\n",
    "\n",
    "# split\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, stratify=df['author'], random_state=42)\n",
    "\n",
    "# centroid\n",
    "train_df['vector'] = train_df['sequence'].apply(lambda t: extract_freq_vector(t, vocab_idx))\n",
    "\n",
    "author_centroids = {}\n",
    "for author, group in train_df.groupby('author'):\n",
    "    vectors = np.vstack(group['vector'])\n",
    "    centroid = vectors.mean(axis=0)\n",
    "    author_centroids[author] = centroid\n",
    "\n",
    "# classifying\n",
    "def classify(text):\n",
    "    text_cleaned = clean_text(text)  # clean input text too\n",
    "    vec = extract_freq_vector(text_cleaned, vocab_idx)\n",
    "    sims = {}\n",
    "    for author, centroid in author_centroids.items():\n",
    "        similarity = cosine_similarity([vec], [centroid])[0][0]\n",
    "        sims[author] = similarity\n",
    "    predicted_author = max(sims, key=sims.get)\n",
    "    return predicted_author\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "#baseline accuracy is th word frequency centroid + cosine similarity.. NO burrows delta. NO text distort\n",
    "for i, row in test_df.iterrows():\n",
    "    pred_author = classify(row['sequence'])\n",
    "    correct += (pred_author == row['author'])\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\nbaseline accuracy: {accuracy:.4f}\")\n",
    "#feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a7d22-fa4c-447a-9632-9eb6efc505f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
